---
layout:     post
title:      Linux设备驱动中的并发控制（一）
subtitle:   Linux驱动
date:       2018-7-11
author:     Muggle
header-img:
catalog: 	 true
tags:
    - Linux驱动
---
# Question
>Linux设备驱动中的并发控制理解的大致流程如下：<br>
>1.并发和竞态的概念及发生场合
>2.编译乱序、执行乱序的问题，以及内存屏障
>3.并发控制机制：中断屏蔽、原子操作、自旋锁、信号量和互斥体
>4.并发控制后的globalmem的设备驱动

# 一、并发与竞态
## 1.概念
并发是指多个执行单元同时、并行执行，而并发的执行单元对临界区共享资源的访问会很容易导致竞态的发生 。
## 2.并发和竞态的发生场景：
①对称多处理器的多个CPU<br>
②中断和进程之间
# 二、原子操作
  原子操作可以保证一个整型数据的修改是排他性的。分为两类原子操作，分别针对位和整型变量的原子操作（依赖于CPU底层的原子操作）<br>
![](https://i.imgur.com/iIyNnK3.jpg)
  如果有两个CPU程序并发，在T1-T4的时间点上由于CPU0在T1进入，而CPU1在T2进入，它们调用ldrex+strex是同时的，关键在于进入的时间点不同，所以CPU0会先执行，CPU1执行失败进入循环等待<br>
  ## 1.整型原子操作
  ###设置原子变量的值

	void atomic_set(atomic_t *v,int i);	//设置原子变量值为i
	atomic_t v = ATOMIC_INIT(0);		//定义原子变量i并初始化为0


###获取原子变量的值
	atomic_read(atomic_t *v);			//返回原子变量的值
###原子变量加减
	void atomic_add(int i,atomic_t *v);	//原子变量加i
	void atomic_sub(int i,atomic_t *v);	//原子变量减i
###原子变量自增/自减
	void atomic_inc(atomic_t *v);	//自身加1
	void atomic_dec(atomic_t *v);	//自身减1
###原子变量自减测试
	void atomic_dec_and_test(atomic_t *v);	//该函数对原子类型的变量v原子的减少1，并判断结果是否是0，如果是0,返回真，否则返回假。
###原子变量自增测试
	void atomic_inc_and_test(atomic_t *v)	//该函数对原子类型的变量v原子增加1，并判断结果是否是0，如果是0，返回真，否则返回假。
###原子变量加减测试
	void atomic_add_negative(int i, atomic_t *v);	//该函数对原子类型的变量v原子的增加I，并判断结果是否是负数，如果是，返回真，否则返回假。
###返回指针的原子变量加减
	void atomic_add_return(int i, atomic_t *v)；
	void atomic_sub_return(int i, atomic_t *v)；
##2.位原子操作
###设置位写1
	void set_bit(int nr, volatile void* addr);        //设置地址addr的第nr位,所谓设置位,就是把位写为1;
###清除位置0
	void clear_bit(int nr, volatile void* addr);      //清除地址addr的第nr位,所谓清除位,就是把位写为0;
###反转位
	void change_bit(int nr, volatile void* addr);     //把地址addr的第nr位反转;
###测试位
	int test_bit(int nr, volatile void* addr);    //返回地址addr的第nr位;
###测试并操作位
	int test_and_set_bit(int nr, volatile void* addr);    //测试并设置位;若addr的第nr位非0,则返回true; 若addr的第nr位为0,则返回false;
	int test_and_clear_bit(int nr, volatile void* addr);    //测试并清除位;
	int test_and_change_bit(int nr, volatile void* addr);    //测试并反转位;

###举个简单的例子
为了实现设备只能被一个进程打开，从而避免竞态的出现。
	
**static atomic_t scull_available = ATOMIC_INIT(1);      //init atomic
**	
在scull_open 函数和scull_close函数中：

	static atomic_t scull_available = ATOMIC_INIT(1);      //init atomic
	int scull_open(struct inode *inode, struct file *filp)
	{
	    struct scull_dev *dev;         // device information
	
	    dev = container_of(inode->i_cdev, struct scull_dev, cdev);
	    filp->private_data = dev;         // for other methods 
	    if(!atomic_dec_and_test(&scull_available)){
	        atomic_inc(&scull_available);
	        return -EBUSY;
	    }
	    return 0;         // success 
	}
	
	int scull_release(struct inode *inode, struct file *filp)
	{
	    atomic_inc(&scull_available);
	    return 0;
	}

**if(!atomic_dec_and_test(&scull_available)){
	        atomic_inc(&scull_available);
	        return -EBUSY;
	    }
	    return 0;** 
和
**atomic_inc(&scull_available);
**
#三、自旋锁	
##1.自旋锁的使用
自旋锁是一种典型的对临界资源进行互斥访问的手段为了获得一个自旋锁，在某 CPU 上运行的代码需先执行一个**原子操作**，该操作测试并**设置某个内存变量**，如果测试结果表示**锁已经空闲**，则程序**获得这个自旋锁并继续执行**，如果测试结果表明**锁仍被占用**，程序将在一个小的**循环内重复这个"测试并设置"操作**。<br>
当然当锁的持有者通过重置该变量释放这个锁后，某个等待的操作向其使用者报告锁已释放。

理解锁最简单的方法是把它作为一个变量看待。
###1.1定义自旋锁
	spinlock_t lock;
###1.2初始化自旋锁
	spin_lock_init(lock);
###1.3获得自旋锁
	spin_lock(lock);
###1.4释放锁
	spin_unlock(lock);
###1.5大致流程
	

    获得自旋锁，

    获得，返回

    不能获得，自旋在那里

    spin_trylock(lock);

    尝试获得自旋锁，

    能立即获得锁，获得锁返回 真

    不能获得，返回 假
**1.6自旋锁主要针对 SMP 或单 CPU 单内核支持可抢占的情况，使临界区不受别的 CPU 和本 CPU 内的抢占进程打扰，但是得到锁的代码路径在执行临界区的时候，还可能受到中断和底半部的影响。解决办法是：**
	

    spin_lock_irq() = spin_lock() + local_irq_disable() /* 关中断加锁 */

    spin_unlock_irq() = spin_unlock() + local_irq_enable()

    spin_lock_irqsave() = spin_lock() + local_irq_save()

    spin_lock_irqrestore() = spin_unlock() + local_irq_restore()

    spin_lock_bh() = spin_lock() + local_bh_disable() /* 关底半部加锁 */

    spin_unlock_bh() = spin_unlock() + local_bh_enable()
###例子，使用自旋锁实现一个设备只能被一个进程打开
**程序的思路是在驱动中声明一个变量初始化为0，当第一次打开时，加1（此部分用自旋锁保护一下），在open函数中检查flag，如果是1，则返回。在release函数中flag减1（此部分也要加锁保护下）**

	int flag = 0;
 
	struct hello_device
	{
	    char data[128];
	    spinlock_t lock;
	    struct cdev cdev;
	} hello_device;
	 
	 
	static int hello_open (struct inode *inode, struct file *file)
	{
	    spin_lock(&hello_device.lock);>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	    if ( flag )
	    {
	        spin_unlock(&hello_device.lock);>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	        return -EBUSY;
	    }
	    flag++;
	    spin_unlock(&hello_device.lock);>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	 
	    printk (KERN_INFO "Hey! device opened\n");
	 
	    return 0;
	}
	 
	static int hello_release (struct inode *inode, struct file *file)
	{
	    spin_lock(&hello_device.lock);>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	    flag--;
	    spin_unlock(&hello_device.lock);>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	    printk (KERN_INFO "Hmmm... device closed\n");
	 
	    return 0;
	}

##注意事项
**1.自旋锁主要针对于SMP（多处理器）或单CPU但**内核可抢占**的情况，自旋锁期间，内核抢占被禁止。

2.在多核情况下，任何一个核拿到自旋锁，抢占调度暂时禁止，但是其它没有拿到自旋锁的核并没有被禁止。**
<br>
###特别注意事项
1.自旋锁实际上是**忙等锁**，当锁不可获得时，CPU循环执行“测试并设置”该锁直到可以获得该锁。**只有在占用锁时间极短的情况下，使用自旋锁才合理。**
，如果临界区很大，需要长时间占用锁时，使用自旋锁会降低系统的性能。<br>
2.自旋锁可能会导致系统死锁。**递归使用自旋锁**，即一个已经拥有自旋锁的CPU想第二次使用这个锁，则CPU将会死锁。<br>
3.在自旋锁锁定期间不允许调用可能引起进程调度的程序。如果进程获得自旋锁后再阻塞，如copy_from_user(),copy_to_user(),kmalloc(),msleep(),则会导致内核崩溃。<br>
##2.读写自旋锁
自旋锁的衍生锁读写自旋锁（rwlock）允许读的并发。在写操作方面，最多只允许一个写进程；在读操作方面，可以同时有多个读执行单元。注意：**读和写不能同时进行**。<br>
###2.1定义和初始化自旋锁
	rwlock_t my_rwlock = RW_LOCK_UNLOCKED; /* 静态初始化 */
	rwlock_t my_rwlock;
	rwlock_init(&my_rwlock); /* 动态初始化 */
###2.2读锁定
	void read_lock(rwlock_t *lock);

	void read_lock_irqsave(rwlock_t *lock, unsigned long flags);

	void read_lock_irq(rwlock_t *lock);

	void read_lock_bh(rwlock_t *lock);
###2.2读解锁
	void read_unlock(rwlock_t *lock);

	void read_unlock_irqresore(rwlock_t *lock, unsigned long flags);

	void read_unlock_irq(rwlock_t *lock);

	void read_unlock_bh(rwlock_t *lock);
<br><br>
###2.3写锁定
	void write_lock(rwlock_t *lock);

	void write_lock_irqsave(rwlock_t *lock, unsigned long flags);

	void write_lock_irq(rwlock_t *lock);

	void write_lock_bh(rwlock_t *lock);

	void write_trylock(rwlock_t *lock);

###2.3写解锁
	void write_unlock(rwlock_t *lock);

	void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);

	void write_unlock_irq(rwlock_t *lock);

	void write_unlock_bh(rwlock_t *lock);
###使用举例
	定义rwlock
	初始化rwlock

	读时获取锁
	/* 临界资源 */
	读解锁

	写时获取锁
	/* 临界资源 */
	写解锁
##3.顺序锁
 循序锁是对读写锁的一种优化，读执行单元不会被写执行单元阻塞，但是写执行单元与写执行单元之间是互斥的：

    ● 如果有写执行单元在进行写操作，其他写执行单元必须自旋在那里，直到写执行单元释放了顺序锁

    ● 如果读执行单元在读操作期间，写执行单元已经发生了写操作，那么，读执行单元必须重新读取数据

###限制
**要求被保护的共享资源不含指针，因为写执行单元可能使得指针失效，但读执行单元如果正在访问该指针，将导致 oops。
**
###3.1写执行单元
获取顺序锁：
	
    void write_seqlock(seqlock *sl);

    void write_tryseqlock(seqlock *sl);

    write_seqlock_irqsave(lock, flags); = local_irq_save() + write_seqlock()

    write_seqlock_irq(lock, flags); = local_irq_disable() + write_seqlock()

    write_seqlock_bh(lock, flags); = local_bh_disable() + write_seqlock()
<br>
释放顺序锁：
	
    void write_sequnlock(seqlock *sl);

    write_sequnlock_irqrestore(lock, flags); = write_sequnlock() + local_irq_restore()

    write_sequnlock_irq(lock, flags); = write_sequnlock() + local_irq_enable()

    write_sequnlock_bh(lock, flags); = write_sequnlock() + local_bh_enable()
###读执行单元
读开始：
	
    unsigned read_seqbegin(const seqlock_t *sl);

    read_seqbegin_irqsave(lock, flags); = local_irq_save() + read_seqbegin()
读执行单元在被顺序锁 sl 保护的共享资源进行访问需要调用该函数，该函数仅返回顺序锁 sl 的当前顺序号<br>
重读：
	
    int read_seqretry(const seqlock_t *sl, unsigned iv);

    read_seqretry_irqrestore(lock, iv, flags); = read_seqretry() + local_irq_restore()
读执行单元在访问完被顺序锁 sl 保护的共享资源后需要调用该函数来检查，在读访问期间是否有写操作。如果有写操作，读执行单元需要重新进行读操作。<br>
**使用顺序锁的格式：
**
	
    do{

        seqnum = read_seqbegin(&seqlock_a);

        /* 读操作代码块 */

        ...

    }while (read_seqretry(&seqlock_a, seqnum));

#4.RCU(读-拷贝-更新)
RCU 是 Read-Copy Update 的缩写，读-拷贝-更新，他是基于其原理命名的，对于被 RCU 保护的共享资源，读执行单元不需要获得任何锁就可以访问它，不使用原子执行，而且在除alpha的所有架构上也不需要内存屏障，因此不会导致锁竞争、内存延迟以及流水线停滞。<br>
使用 RCU 的写执行单元在访问他前需要首先拷贝一个副本，然后对副本进行修改，最后使用一个回调机制在适当的时机吧指向原来数据的指针重新指向新的被修改的数据，这个时机就是所有引用该数据 CPU 都退出对共享数据的操作的时候，读执行单元没有任何的同步开销，写执行单元的同步开销则取决于使用的写执行单元之间同步机制。

## 一、为何有RCU这种同步机制呢？

前面我们讲了spin lock，rw spin lock和seq lock，为何又出现了RCU这样的同步机制呢？这个问题类似于问：有了刀枪剑戟这样的工具，为何会出现流星锤这样的兵器呢？每种兵器都有自己的适用场合，内核同步机制亦然。RCU在一定的应用场景下，解决了过去同步机制的问题，这也是它之所以存在的基石。本章主要包括两部分内容：一部分是如何解决其他内核机制的问题，另外一部分是受限的场景为何？

###1、性能问题

我们先回忆一下spin lcok、RW spin lcok和seq lock的基本原理。对于spin lock而言，临界区的保护是通过next和owner这两个共享变量进行的。线程调用spin_lock进入临界区，这里包括了三个动作：

（1）获取了自己的号码牌（也就是next值）和允许哪一个号码牌进入临界区（owner）

（2）设定下一个进入临界区的号码牌（next++）

（3）判断自己的号码牌是否是允许进入的那个号码牌（next == owner），如果是，进入临界区，否者spin（不断的获取owner的值，判断是否等于自己的号码牌，对于ARM64处理器而言，可以使用WFE来降低功耗）。

注意：（1）是取值，（2）是更新并写回，因此（1）和（2）必须是原子操作，中间不能插入任何的操作。

线程调用spin_unlock离开临界区，执行owner++，表示下一个线程可以进入。

RW spin lcok和seq lock都类似spin lock，它们都是基于一个memory中的共享变量（对该变量的访问是原子的）。我们假设系统架构如下：
![](https://i.imgur.com/27fJG7o.gif)
当线程在多个cpu上争抢进入临界区的时候，都会操作那个在多个cpu之间共享的数据lock（玫瑰色的block）。cpu 0操作了lock，为了数据的一致性，cpu 0的操作会导致其他cpu的L1中的lock变成无效，在随后的来自其他cpu对lock的访问会导致L1 cache miss（更准确的说是communication cache miss），必须从下一个level的cache中获取，同样的，其他cpu的L1 cache中的lock也被设定为invalid，从而引起下一次其他cpu上的communication cache miss。

RCU的read side不需要访问这样的“共享数据”，从而极大的提升了reader侧的性能。

###2、reader和writer可以并发执行

spin lock是互斥的，任何时候只有一个thread（reader or writer）进入临界区，rw spin lock要好一些，允许多个reader并发执行，提高了性能。不过，reader和updater不能并发执行，RCU解除了这些限制，允许一个updater（不能多个updater进入临界区，这可以通过spinlock来保证）和多个reader并发执行。我们可以比较一下rw spin lock和RCU，参考下图：
![](https://i.imgur.com/TQPsWVB.gif)
rw-rcu

rwlock允许多个reader并发，因此，在上图中，三个rwlock reader愉快的并行执行。当rwlock writer试图进入的时候（红色虚线），只能spin，直到所有的reader退出临界区。一旦有rwlock writer在临界区，任何的reader都不能进入，直到writer完成数据更新，立刻临界区。绿色的reader thread们又可以进行愉快玩耍了。rwlock的一个特点就是确定性，白色的reader一定是读取的是old data，而绿色的reader一定获取的是writer更新之后的new data。RCU和传统的锁机制不同，当RCU updater进入临界区的时候，即便是有reader在也无所谓，它可以长驱直入，不需要spin。同样的，即便有一个updater正在临界区里面工作，这并不能阻挡RCU reader的步伐。由此可见，RCU的并发性能要好于rwlock，特别如果考虑cpu的数目比较多的情况，那些处于spin状态的cpu在无谓的消耗，多么可惜，随着cpu的数目增加，rwlock性能不断的下降。RCU reader和updater由于可以并发执行，因此这时候的被保护的数据有两份，一份是旧的，一份是新的，对于白色的RCU reader，其读取的数据可能是旧的，也可能是新的，和数据访问的timing相关，当然，当RCU update完成更新之后，新启动的RCU reader（绿色block）读取的一定是新的数据。

###3、适用的场景

我们前面说过，每种锁都有自己的适用的场景：spin lock不区分reader和writer，对于那些读写强度不对称的是不适合的，RW spin lcok和seq lock解决了这个问题，不过seq lock倾向writer，而RW spin lock更照顾reader。看起来一切都已经很完美了，但是，随着计算机硬件技术的发展，CPU的运算速度越来越快，相比之下，存储器件的速度发展较为滞后。在这种背景下，获取基于counter（需要访问存储器件）的锁（例如spin lock，rwlock）的机制开销比较大。而且，目前的趋势是：CPU和存储器件之间的速度差别在逐渐扩大。因此，那些基于一个multi-processor之间的共享的counter的锁机制已经不能满足性能的需求，在这种情况下，RCU机制应运而生（当然，更准确的说RCU一种内核同步机制，但不是一种lock，本质上它是lock-free的），它克服了其他锁机制的缺点，但是，甘蔗没有两头甜，RCU的使用场景比较受限，主要适用于下面的场景：

（1）RCU只能保护动态分配的数据结构，并且必须是通过指针访问该数据结构

（2）受RCU保护的临界区内不能sleep（SRCU不是本文的内容）

（3）读写不对称，对writer的性能没有特别要求，但是reader性能要求极高。

（4）reader端对新旧数据不敏感。

 

##三、RCU的基本思路

###1、原理

RCU的基本思路可以通过下面的图片体现：
![](https://i.imgur.com/8QdrlNE.gif)


RCU涉及的数据有两种，一个是指向要保护数据的指针，我们称之RCU protected pointer。另外一个是通过指针访问的共享数据，我们称之RCU protected data，当然，这个数据必须是动态分配的  。对共享数据的访问有两种，一种是writer，即对数据要进行更新，另外一种是reader。如果在有reader在临界区内进行数据访问，对于传统的，基于锁的同步机制而言，reader会阻止writer进入（例如spin lock和rw spin lock。seqlock不会这样，因此本质上seqlock也是lock-free的），因为在有reader访问共享数据的情况下，write直接修改data会破坏掉共享数据。怎么办呢？当然是移除了reader对共享数据的访问之后，再让writer进入了（writer稍显悲剧）。对于RCU而言，其原理是类似的，为了能够让writer进入，必须首先移除reader对共享数据的访问，怎么移除呢？创建一个新的copy是一个不错的选择。因此RCU writer的动作分成了两步：

（1）removal。write分配一个new version的共享数据进行数据更新，更新完毕后将RCU protected pointer指向新版本的数据。一旦把RCU protected pointer指向的新的数据，也就意味着将其推向前台，公布与众（reader都是通过pointer访问数据的）。通过这样的操作，原来read 0、1、2对共享数据的reference被移除了（对于新版本的受RCU保护的数据而言），它们都是在旧版本的RCU protected data上进行数据访问。

（2）reclamation。共享数据不能有两个版本，因此一定要在适当的时机去回收旧版本的数据。当然，不能太着急，不能reader线程还访问着old version的数据的时候就强行回收，这样会让reader crash的。reclamation必须发生在所有的访问旧版本数据的那些reader离开临界区之后再回收，而这段等待的时间被称为grace period。

顺便说明一下，reclamation并不需要等待read3和4，因为write端的为RCU protected pointer赋值的语句是原子的，乱入的reader线程要么看到的是旧的数据，要么是新的数据。对于read3和4，它们访问的是新的共享数据，因此不会reference旧的数据，因此reclamation不需要等待read3和4离开临界区。

###2、基本RCU操作

对于reader，RCU的操作包括：

（1）rcu_read_lock，用来标识RCU read side临界区的开始。

（2）rcu_dereference，该接口用来获取RCU protected pointer。reader要访问RCU保护的共享数据，当然要获取RCU protected pointer，然后通过该指针进行dereference的操作。

（3）rcu_read_unlock，用来标识reader离开RCU read side临界区

对于writer，RCU的操作包括：

（1）rcu_assign_pointer。该接口被writer用来进行removal的操作，在witer完成新版本数据分配和更新之后，调用这个接口可以让RCU protected pointer指向RCU protected data。

（2）synchronize_rcu。writer端的操作可以是同步的，也就是说，完成更新操作之后，可以调用该接口函数等待所有在旧版本数据上的reader线程离开临界区，一旦从该函数返回，说明旧的共享数据没有任何引用了，可以直接进行reclaimation的操作。

（3）call_rcu。当然，某些情况下（例如在softirq context中），writer无法阻塞，这时候可以调用call_rcu接口函数，该函数仅仅是注册了callback就直接返回了，在适当的时机会调用callback函数，完成reclaimation的操作。这样的场景其实是分开removal和reclaimation的操作在两个不同的线程中：updater和reclaimer。

#浅谈RCU机制
说道读读多写少的场景，我们能自然联想到读写锁，不错，RCU正是和读写锁相似的一种提高读多写少场景下代码执行效率的机制，它的核心思想就是“订阅发布”机制。<br>

实际上，我们使用锁来保护互斥资源，无非就是防止这两种情况：

1）读者在读取数据时，写者对数据同时进行改写，导致读者读到不完整的数据<br>
2）写者在写数据时，有另一写者同时写数据，导致数据被写脏<br>
由此我们很早久已经使用了各种锁机制来保护互斥资源，而且针对读多写少的情况，我们还专门优化出读写锁，使得在没有写者的情况下，多个读者可以并行持锁，从而可以并行读取数据，提高效率。那么有没有一种去锁的办法实现对互斥资源的保护呢？所以这里RCU机制就登场了。它的核心思想是：互斥数据采用指针来访问，当写者想要更新数据时，先将数据复制一份，对复制的数据进行修改，这样可以不干扰同一时间正在读取数据的读者。当修改完毕后，通过指针赋值，将旧数据指针更新指向到新的数据。最后再完成对旧数据的释放，释放时需要等待正在使用之前旧数据的读者退出临界区，而等待的这段时间在RCU机制中被称作“宽限期”。这里几个重要的概念就是“写时复制”、“指针赋值”、以及“宽限期”。它就像杂志订阅和发布，读者读取数据就好比订阅杂志，写者<br>
复制并修改数据好比杂志的编辑，最后通过指针赋值更新数据久好比杂志的发布，而宽限期等待就好比期刊的发布周期，所以这是一个形象的比喻。通过这种机制，我们可以实现读者的去锁，它有如下几个特点：

1）读者读取数据不需要枷锁，因为数据时通过指针赋值更新的，而现代CPU处理器基本都可以保证指针赋值的原子性，另外写者保证在指针赋值前数据已经修改好，所以读者读到的数据始终是完整的，无需加锁<br>
2）写者必须通过“写时复制”和“指针赋值”的方式更新数据，而对旧数据释放前需要等待数据更新前已经读取了旧数据的读者完成对旧数据的使用。<br>
3）写者和写者直接仍然需要锁来互斥同步，但由于RCU的使用场景时多读写少，所以开销是可以接受的。<br>

内核文档明确指出了一个RCU数据更新的典型步骤：

a. Remove pointers to a data structure, so that subsequent
readers cannot gain a reference to it.

b. Wait for all previous readers to complete their RCU read-side
critical sections.

c. At this point, there cannot be any readers who hold references
to the data structure, so it now may safely be reclaimed
(e.g., kfree()d).

翻译：

a. (通常是从链表中)移除指向数据结构(通常是链表节点)的指针, 使得后续读者无法再(通过链表)引用这个数据

b. 等待移除数据之前已经读取并正在使用该数据的读者退出临界区

c. 此时，已经没有读者在使用这个数据结构了，因此它可以被安全的回收

举个例子，比如有如下这样一个链表：

      ____       ____       ____
-->|__A_|-->|__B_|-->|__C_|-->...

现需要将B链表回收，那么：

a. 先将B节点从链表中移除，此后则不会再有读者能访问到B节点了，移除后情况如下：

      ____       ____                       ____
-->|__A_|-->|__C_|-->...     N-->|__C_|

其中“N”表示此时正在使用C节点的N个读者，虽然C已经不在链表当中，但仍有读者持有指向C的指针，所以暂时C的内存还不能回收

b. 等待所以正在使用C节点的读者使用完毕，即退出临界区，此时情况如下：

      ____       ____                      ____ 
-->|__A_|-->|__C_|-->...     0-->|__C_|

“0”表示已经没有读者使用C节点了，因此可以安全回收

c. 销毁C节点，回收内存：

      ____       ____            
-->|__A_|-->|__C_|-->...   

d. 如果不想删除B，而只是想更新B的内容，那么此时便以安全的修改，修改完毕后果再将B节点以原子的方式插回队列中，如下：

      ____       ____       ____ 
-->|__A_|-->|__B_|-->|__C_|-->...

那么，这里有几个关键点没有讲清楚：

1. 如何知道当前有那些读者进程正在使用C节点呢？

2. 读者全部退出临界区的时候，如果通知出来呢？

所以，内核要给我们提供API去完成这些事情，请继续往下看。<br>

###【RCU的核心API】

内核文档列出了如下几个核心API函数：

a. rcu_read_lock()
b. rcu_read_unlock()
c. synchronize_rcu() / call_rcu()
d. rcu_assign_pointer()
e. rcu_dereference()
就是说这5个API时最基本的，还有其他一些API，但是都可以通过这5个API的组合来实现，下面一一讲解：

a. void rcu_read_lock(void);
翻译：用于通知回收者当前读者已进入临界区，在读者的临界区里时不允许阻塞的。

b. void rcu_read_unlock(void);
用于通知回收者当前读者已经退出临界区。

c. void synchronize_rcu(void);
synchronize_rcu用于等待在synchronize_rcu调用之前通过rcu_read_lock进入临界区的读者（在synchronize_rcu调用之后进入临界区的并不关心），在此之前函数会一直阻塞，当返回时，旧数据可以被安全的释放。<br>

内核文档还给了一个例子，自己体会：
      CPU 0                            CPU 1                             CPU 2
-----------------           -------------------------              ---------------
1. rcu_read_lock()
2.                         enters synchronize_rcu()
3.                                                                       rcu_read_lock()
4. rcu_read_unlock()
5.                          exits synchronize_rcu()
6.                                                                      rcu_read_unlock()

d.typeof(p) rcu_assign_pointer(p, typeof(p) v);

这是一个宏实现，也只能是宏，自己体会下（提示：typeof。。。）
引用一段内核文档原话：The updater uses this function to assign a new value to an RCU-protected pointer, in order to safely communicate the change in value from the updater to the reader. This function returns the new value, and also executes any memory-barrier instructions required for a given CPU architecture.
这个函数就是用来完成前面提到的“指针赋值”的动作的，它会处理一些内存屏障的情况，否则我们直接赋值就是了，何必用这个宏呢？

e. typeof(p) rcu_dereference(p);

同样时通过宏实现的, 内核文档的解释：
The reader uses rcu_dereference() to fetch an RCU-protected pointer, which returns a value that may then be safely dereferenced. Note that rcu_deference() does not actually dereference the pointer, instead, it protects the pointer for later dereferencing. It also executes any needed memory-barrier instructions for a given CPU architecture.

这段话比较难懂，但说白了就是，当你想获取一个指向某个RCU数据时，rcu_dereference能返回一个安全的引用。 这里dereference是个很有意思的词，大家可以查下reference和dereference的区别，很好玩。

 

 

##【总结】

理解RCU机制的关键点就是如何去理解“订阅发布”，确实如此，我们在APP商店购买应用的时候，用户得到的都是一个完整可用的APK，即最终产品的样子，而应用的开发过程是不会让用户看到的。作者要更新软件时，会线下修改，改好之后推送更新，即发布。同理，RCU机制在更新数据时，先将数据从链表中移除（类似商品下架），然后等待正在使用该数据的读者使用完毕，这段时间我们叫“宽限期”（类似以下架应用仍然继续提供客服，但会有一个期限），等宽限期过后，便修改跟新，然后重新插回链表中（类似应用重新上架）。这是一个非常巧妙的设计，需要花些时间去理解，但是一旦理解， 就很容易掌握这些概念了，甚至不需要任何记忆。

参考自：
>[http://www.wowotech.net/kernel_synchronization/rcu_fundamentals.html](http://www.wowotech.net/kernel_synchronization/rcu_fundamentals.html)
[https://www.cnblogs.com/yanghaizhou/p/6286347.html](https://www.cnblogs.com/yanghaizhou/p/6286347.html)

更详细的关于RCU的分析请参考：
[https://blog.csdn.net/xiaofeng_yan/article/details/43967115](https://blog.csdn.net/xiaofeng_yan/article/details/43967115)

